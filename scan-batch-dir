#!/usr/bin/python3
import yaml
import argparse
import os
import pwd
import json
import sys
import subprocess
import shutil
import logging
import openpyxl
import csv
import io
import pandas as pd

# import from functions.py
#from functions import *

def get_username() -> str:
    """
    Retrieves the current logged-in user's username.

    Returns:
        str: The username of the current user.
    """
    return pwd.getpwuid(os.getuid())[0]

def create_temp_dir_at_path(path: str) -> str:
    """Creates a temporary directory at the specified path.

    Args:
        path: The path where the temporary directory should be created.

    Returns:
        The path to the created temporary directory.
    """
    temp_dir = tempfile.mkdtemp(dir=path)
    return temp_dir

def read_yaml_file(path: str) -> dict:
    """
    Reads a YAML file and returns its content as a dictionary.

    Args:
        path (str): The path to the YAML file.

    Returns:
        dict: The content of the YAML file.

    Raises:
        FileNotFoundError: If the file does not exist.
        yaml.YAMLError: If there is an error parsing the YAML file.
        ValueError: If the file content is not a valid dictionary.
    """
    try:
        with open(path, "r") as stream:
            data = yaml.safe_load(stream)
            if not isinstance(data, dict):
                raise ValueError(f"The file content is not a valid dictionary: {path}")
            return data
    except FileNotFoundError:
        print(f"File not found: {path}. Please check the file path and try again.")
        raise
    except yaml.YAMLError:
        print(f"Error parsing YAML file: {path}. Please ensure the file is properly formatted.")
        raise
    except ValueError:
        print(f"Invalid content in YAML file: {path}.")
        raise
    except Exception as e:
        print(f"An unexpected error occurred while reading the YAML file: {str(e)}")
        raise e

def connect_to_google_sheet(credentials_file: str):
    """
    Connects to the Google Sheets API using service account credentials.

    Args:
        credentials_file (str): Path to the Google service account credentials file.

    Returns:
        build: The Google Sheets API service object.
    """
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
    CONFIG_FILE = credentials_file

    if not os.path.exists(CONFIG_FILE):
        raise Exception(f"Configuration file not found: {CONFIG_FILE}")

    try:
        creds = service_account.Credentials.from_service_account_file(
            CONFIG_FILE,
            scopes=SCOPES
        )

        service = build('sheets', 'v4', credentials=creds)
        return service

    except Exception as e:
        raise Exception(f"Failed to create Google Sheets service: {str(e)}")

def read_google_sheet(spreadsheet_id: str, sheet_name="Sheet1", credentials_file="configuration.json") -> pd.DataFrame:
    """
    Reads data from a Google Sheet into a pandas DataFrame.

    Args:
        spreadsheet_id (str): The ID of the Google Sheet.
        sheet_name (str): The name of the sheet to read data from.
        credentials_file (str): Path to the Google service account credentials file.

    Returns:
        pandas.DataFrame: The data from the Google Sheet.
    """
    try:
        # Build the service
        service = connect_to_google_sheet(credentials_file);

        # Call the Sheets API
        sheet = service.spreadsheets()
        result = sheet.values().get(spreadsheetId=spreadsheet_id,
                              range=sheet_name).execute()

        # Get the values
        values = result.get('values', [])

        if not values:
            print('No data found.')
            return pd.DataFrame()

        # Convert to DataFrame
        # First row as headers, rest as data
        headers = values[0]
        data = values[1:] if len(values) > 1 else []

        # Create DataFrame
        df = pd.DataFrame(data, columns=headers)

        return df

    except Exception as e:
        print(f"An error occurred: {str(e)}")
        return pd.DataFrame()

def update_google_sheet(df: pd.DataFrame, spreadsheet_id: str, sheet_name: str, credentials_file: str) -> tuple:
    """
    Updates a Google Sheet with data from a pandas DataFrame.

    Args:
        df (pandas.DataFrame): The DataFrame containing updated data.
        spreadsheet_id (str): The ID of the Google Sheet.
        sheet_name (str): The name of the sheet to update.
        credentials_file (str): Path to the Google service account credentials file.

    Returns:
        tuple: Success status and message.
    """
    try:
        # Validate inputs
        if not isinstance(df, pd.DataFrame):
            return False, "Input must be a pandas DataFrame"

        if df.empty:
            return False, "DataFrame is empty"

        # Build the service
        service = connect_to_google_sheet(credentials_file);

        # Call the Sheets API
        sheet = service.spreadsheets()

        # Convert DataFrame to list of lists (including headers)
        values = [df.columns.tolist()] + df.values.tolist()

        # Prepare the body for the API request
        body = {
            'values': values
        }

        # Update the sheet with DataFrame contents
        result = sheet.values().update(
            spreadsheetId=spreadsheet_id,
            range=f'{sheet_name}!A1',
            valueInputOption='RAW',
            body=body
        ).execute()

        updated_cells = result.get('updatedCells', 0)
        return True, f"Successfully updated {updated_cells} cells"

    except Exception as e:
        return False, f"An error occurred: {str(e)}"

def update_dataframe(df: pd.DataFrame, match_column: str, match_value, update_column: str, update_value):
    """
    Update a DataFrame by matching a value in a specified column and updating another column.

    Parameters:
    df (pandas.DataFrame): The input DataFrame
    match_column (str): Name of the column to match on
    match_value: Value to match in the match_column
    update_column (str): Name of the column to update
    update_value: Value to set in the update_column

    Returns:
    pandas.DataFrame: Updated DataFrame
    boolean: True/False
    str: Message
    """
    try:
        # Verify input is a DataFrame
        if not isinstance(df, pd.DataFrame):
            return None, False, "Input must be a pandas DataFrame"

        # Check if DataFrame is empty
        if df.empty:
            return df, False, "DataFrame is empty"

        # Verify columns exist
        if match_column not in df.columns:
            return df, False, f"Match column '{match_column}' not found"
        if update_column not in df.columns:
            return df, False, f"Update column '{update_column}' not found"

        # Create a copy to avoid modifying the original
        updated_df = df.copy()

        # Find rows to update
        mask = updated_df[match_column].astype(str) == str(match_value)
        if not mask.any():
            return updated_df, False, f"No rows found matching '{match_value}' in '{match_column}'"

        # Update the matching rows
        updated_df.loc[mask, update_column] = update_value

        # Count updated rows
        updated_count = mask.sum()

        return updated_df, True, f"Successfully updated {updated_count} row(s)"

    except Exception as e:
        return df, False, f"An error occurred: {str(e)}"

def value_exists_in_column(df, column_name, value):
    """
    Checks if a value exists in a column in a Pandas DataFrame.

    Args:
        df (pd.DataFrame): Pandas DataFrame to search in.
        column_name (str): Name of the column to search in.
        value: Value to search for.

    Returns:
        bool: True if the value exists, False otherwise.
    """

    try:
        # Check if the column exists in the DataFrame
        if column_name not in df.columns:
            return False
            #raise ValueError(f"The column '{column_name}' does not exist in the DataFrame")

        # Check if the value exists in the column
        return value in df[column_name].values

    except Exception as e:
        #print(f"An unexpected error occurred: {e}")
        return False

def scan_directory(directory):
    """
    Recursively scan a directory and return a list of files and subdirectories.
    
    Args:
        directory (str): Path to the directory to scan.
    
    Returns:
        list: List of tuples containing file/subdirectory name, type, and path.
    """
    result = []
    for item in os.listdir(directory):
        item_path = os.path.join(directory, item)
        if os.path.isfile(item_path):
            result.append((item, "File", item_path))
        elif os.path.isdir(item_path):
            result.append((item, "Directory", item_path))
            result.extend(scan_directory(item_path))  # Recursive call
    return result


def read_csv(csv_file):
    """
    Read a csv file.

    Args:
        csv_file (str): Path to a CSV file.

    Returns:
        data frame (df): A Pandas data frame.
    """
    try:
        df = pd.read_csv(csv_file)
    except FileNotFoundError:
        print(f"Error: The file '{csv_file}' was not found.")
    except pd.errors.EmptyDataError:
        print(f"Error: The file '{csv_file}' is empty.")
    except pd.errors.ParserError as e:
        print(f"Error: An error occurred while parsing the file '{csv_file}' - {e}.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
    return df


def write_csv(df,csv_file):
    """
    Write a csv file.

    Args:
        df (Pandas data frame): Dataframe containing the data to write out.
        csv_file (str): A full path to the resulting CSV file.
    """
    try:
        df.to_csv(csv_file, index=False)
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

def update_csv(df,update_column,condition_column,condition_value,new_value):
    """
    Updates a column field in a pandas dataframe based on another column field.

    Args:
        df (pandas dataframe): pandas dataframe
        update_column (str): Name of the column to update.
        condition_column (str): Name of the column to check the condition
        condition_value (str): Value to check in the condition column.
        new_value (str): New value to update in the update column.

    Returns:
        None
    """

    #print(f"Updating: {condition_column}:{condition_value} field {update_column} with {new_value}")

    try:
        if update_column not in df.columns or condition_column not in df.columns:
            print(f"Error: {update_column} does not exist in the CSV.")
            #raise ValueError("Invalid column name")

        if condition_value not in df[condition_column].values:
            print(f"Error: {condition_column}:{condition_value} does not exist in CSV.")
            #raise ValueError("Condition value not found is not in the manifest.csv")

        df.loc[df[condition_column] == condition_value, update_column] = new_value

    except ValueError as e:
        print(f"Error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
    

def convert_tiff_to_jp2(tif_file_path, jp2_file_path):
    """
    Converts a tif file to a jp2 file using the 'gm convert' command.

    Args:
        tif_file_path (str): A full path the TIFF file.
        jp2_file_path (str): A full path to the resulting JP2 file.
    Returns:
        None 
    """
    args = [
        "/usr/bin/gm",
        "convert",
        "-define",
        "jp2:numrlvls=6",
        "-define",
        "jp2:tilewidth=1024",
        "-define",
        "jp2:tileheight=1024",
        "-define",
        "jp2:rate=1.0",
        "-define",
        "jp2:lazy", 
        "-define",
        "jp2:prg=rlcp",
        "-define",
        "jp2:mode=int",
        "-define", 
        "jp2:ilyrrates='0.015625,0.01858,0.0221,0.025,0.03125,0.03716,0.04419,0.05,0.0625,0.075,0.088,0.1,0.125,0.15,0.18,0.21,0.25,0.3,0.35,0.4,0.5,0.6,0.7,0.84'",
        tif_file_path,
        jp2_file_path
        ]

    try:
        result = subprocess.run(args, capture_output=True, text=True)
        if (result.returncode == 0):
            logger.info(f"Successfully converted TIFF to JP2 on file: {tif_file_path}")
    except Exception as e:
        raise Exception(f"Failed to convert TIFF to JP2: {str(e)}")

def is_valid_dataframe(df: pd.DataFrame) -> bool:
    """
    Determines if a DataFrame is valid (not empty and of correct type).

    Args:
        df (pandas.DataFrame): The DataFrame to validate.

    Returns:
        bool: True if valid, False otherwise.
    """
    return isinstance(df, pd.DataFrame) and not df.empty


def validate_spreadsheet(csv_file):
    required_columns = ['id','title','file','parent_id']

    # Read the CSV file.
    df = pd.read_csv(csv_file)

    # Check for the columns.
    for column_name in required_columns:
        if not column_name in df.columns:
            print(f"Required column {column_name} is missing in the CSV {csv_file} - adding it: {column_name}.")
            # add the required column
            if column_name == 'file':
                df[column_name] = None

    # Write the CSV file.
    #write_csv(df,csv_file) 

def parse_arguments():
    parser = argparse.ArgumentParser(
        description='Migrate media from Islandora 7 to PeerTube.',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    # Required arguments
    parser.add_argument('--config-file', dest="config_file", required=True, help='Path to the YAML configuration file.')
    parser.add_argument('--log-file', dest="log_file", required=True, help='Path to the log file.')
    parser.add_argument('--directory', dest="directory", required=True, help='Path to the directory to scan.')

    # Optional arguments
    parser.add_argument('--in-google-sheet-id', dest="in_gs_id", help='Google Sheet ID related to the directory.')
    parser.add_argument('--in-google-sheet-name', dest="in_gs_name", help='Google Sheet Tab Name.')
    
    # Parse Arguments
    args = parser.parse_args()

    return args

def process_image():
    logger.info(f"Processing an image.")
    # Images are kept at the top level folder.

    # Create additional variables.
    dir,ext = os.path.splitext(file_path)  # Split the file_path into directory and extension.
    pid = os.path.basename(dir)            # Assign pid to the last piece of the directory.
    jp2_path = dir+'.jp2'                  # Construct the jp2 file path based upon the original file path.

    # If it's a .tif it gets converted to .jp2
    if ( ext == ".tif" ):
        print(f"I Converting: {file_path} to jp2.")
        if not os.path.exists(jp2_path):
            convert_tiff_to_jp2(file_path, jp2_path)

    # Update the sheet with the paths.
    #update_csv(df,'file','id',pid,jp2_path)
    #df,success,msg = update_dataframe(df, match_column, match_value, update_column, update_value)

    logger.info(f"Processing an image - complete.")



def process_object():
    logger.info(f"Processing an object.")
    # object files are kept within a folder of the top level folder.

    if (file_type == "File" ) and ( parent != "" ):
        dir,ext = os.path.splitext(file_path)
        pid = os.path.basename(dir)
        jp2_path = dir+'.jp2'
        if ( ext == ".tif" ):
            print(f"M Converting: {file_path} to jp2.")
            if not os.path.exists(jp2_path):
                convert_tiff_to_jp2(file_path, jp2_path)

    # Update the sheet.
    #df,success,msg = update_dataframe(df, match_column, match_value, update_column, update_value)

    logger.info(f"Processing an object - complete.")


def process_directory():
    # folders under the top level folder are considered object folders.
    logger.info(f"Processing a subdirectory.")

    # Update the sheet.
    #df,success,msg = update_dataframe(df, match_column, match_value, update_column, update_value)

    logger.info(f"Processing a subdirectory - complete.")


def process_files(data):
    # Begin Processing the listing of the directory.
    logger.info(f"Processing file data.")

    # Loop through the listing.
    for row, (file_name, file_type, file_path) in enumerate(data, start=2):
        print(f"Inspecting: {file_path}")

        # Skip things we don't want to include.
        if (( file_name == "target.tif" ) or ( file_name == "manifest.csv" ) or ( file_name == "manifest.xlsx" )):
            next
        else:
            # Define the parent
            parent = file_path.replace(directory, "")
            parent = parent.replace("/"+file_name, "")
            parent = parent.replace("/","")

            if ( file_type == "File" ) and ( parent == "" ):
                # This is an Image.
                print(f"Image: {file_path}")
                process_image()

            if (file_type == "File" ) and ( parent != "" ):
                # This is an Object.
                print(f"Object: {file_path}")
                process_object()

            if (file_type == "Directory" ):
                # This is a Directory.
                print(f"Directory: {file_path}")
                process_directory()

    # Write the Sheet.
    #write_csv(df,manifest_path)


    

def main():
    # Setup the log file format.
    log_formatter = logging.Formatter(fmt='%(asctime)s.%(msecs)03d %(levelname)s %(message)s',datefmt="%Y%m%d %H:%M:%S")

    # Parse command line arguements.
    args = parse_arguments()

    # Obtain the user running the script.
    username            = get_username()

    # Get the configuration file contents.
    cfg                 = read_yaml_file(args.config_file)

    # Set Google variables from config file.
    google_credentials  = cfg['google_credentials_file']
    google_sheet_id     = cfg['google_sheet_id']
    google_sheet_name   = cfg['google_sheet_name']

    # Create the Log file.
    print(f"Creating log file: {args.log_file}")
    logger = setup_logger('logger', args.log_file, level=logging.DEBUG, formatter=log_formatter)
    logger.info(f"Begin log.")

    # Get external command paths.
    gm_path = shutil.which("gm")


    if gm_path:
        logger.info(f"GraphicsMagick Executable found at: {gm_path}")
    else:
        logger.error(f"GraphicsMagick Executable 'gm' not found and is required.")
        print(f"GraphicsMagick Executable 'gm' not found and is required.")
        print(f"Exiting...")
        exit()

    # Connect to Google Sheets and read the Sheet to dataframe.
    print(f"Reading Google Sheet: {google_sheet_id},{google_sheet_name}")
    df = read_google_sheet(google_sheet_id, google_sheet_name, google_credentials)
    if (is_valid_dataframe(df)):
        
        # Scan the directory and return a list of directory contents.
        file_data = scan_directory(args.directory)

        # Process the contents.
        process_files(file_data)

    else:
        logger.error(f"Google Sheet is invalid.")
        print(f"Google Sheet is invalid.")
        exit()


if __name__ == "__main__":
    main()


